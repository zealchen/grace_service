Okay. So today I'm going to show you how you can build your own autonomous AI video agent. So what you see here is kind of the logic we are going to follow today. So I'm just going to go through the logic now. Then we're going to head over to cloud code. We're going to gather some context. I'm going to show you how you can set this up yourself.
And I think the results are getting pretty good. So pretty exciting. So uh let's just go through the logic here of what we want to build today. The first thing we will need is of course an YouTube API because uh this agent wants to find the most viewed shorts from the last seven days. So we have something we can try to recreate or emulate. So by using the API we can uh find these shorts and we can get the URLs because Gemini 2.5 Pro can actually uh use an input YouTube URL as context. This is crucial because we want to extract the scenes from this uh popular YouTube video, right? Next is going to be to write the new image and video prompt. So when we have the scene description, we can try to recreate this by creating an image we can use as input context to the cling 2.1 model. And for image generation, we're going to use image and 4 from Google. Uh those two are pretty good and not so expensive. So like I said, generate image because we're going to use that as input context. Yeah, we create this from the prompt. And finally, the clip we can generate is uh we are using the cling model with the image we generated and the prompt uh we generated back here. So that is basically the the setup and the logic.
So what we're going to do next is gather some context. Then we're going to get into cloud code and we're going to run this and we're going to yeah hopefully this goes well and we get some pretty cool interesting results here. So when we're going to do some context engineering, I think it's very important that we do this well so our uh process by creating the code goes very smooth.
So we're going to collect some information from fal here uh both the cling and the image and model. We need some context from Gemini for the video understanding and some from Google. So if we look at the um we can start here on Gemini, right? And they have we have something called video understanding.
This is uh the documentation we need, right? If you scroll down here, you can see we have something called include a YouTube URL. So, we kind of want this. I think we're going to do this in Python.
So, I'm just going to copy this. And I can basically just grab the full page if I wanted to. It doesn't matter too much, but let's grab this. So, I pasted this into my Gemini markdown file here. So, I guess we are set here now for the the input and uh the scene description APIs.
Next, we want to grab something from YouTube. So, I found the relevant uh YouTube data API reference here, and that is going to be videos and list. So, I just copy the full page here, and we just pasted that in to our yeah stuff here. We're going to do the same with the both the file models. I did that. If you want to repeat that, you can just go to let's say cling 2.5 v12 pro uh standard image to image video image to video. You can just click on the API here and you will find the documentation down here. Right? So I just copied that and I just pasted it back in here. So I think we have all the documentation we want now from our model. So that should be good to go. Uh there are a few other things we need to gather before we can run cloud code and that is going to be our API keys. So we need a YouTube API key, a Gemini API key and a foul AI API key to generate videos and images. So the YouTube API key you can find uh in your Google Cloud console. Same with the Gemini API here. So I'm just going to gather those and we should be good to go here. So I'm just going to Yeah, I'm going to do that. Okay. So then we are ready. So I'm just in my terminal here.
I'm just going to launch my cloud and I'm just going to log in. Okay, that was done. So we are logged in. So I'm just going to start by read my project. Just start with that. So we get up to speed on the documentation we have and our environment variables here. So I'm probably just going to skip ahead on this. So you can see we read all the documentation. Now kind of cloud code is ready to work because it has some idea of what we're going to build today.
Okay. So what we're going to do now is we're going to go into plan mode. So you just do shift tab tab. You can see plan mode. This means that we we don't going to use uh do any edits uh in our environment now. So I'm always like to use plan mode and I'm going to do my prompt here. So I'm going to read the prompt if you want to hear it. If not just skip ahead. So good. Now next step is to create a module Python project that will find the top 10 short form content from YouTube in the last 7 days by number of views. When we get the URL from the Google API, we want to send this top URL to Gemini and use this YouTube URL uh input feature as context.
The prompt for Gemini along with the video will be as follows. Extract all the scenes from the video in a structured format with an AI image prompt that will match the scenes. Uh descriptive but simple prompts. This will give us a plan to recreate the most popular short form content from the last seven days. Create a step-by-step plan for this module project. So, I'm just going to run this in plan mode now. And hopefully, we get a nice step-by-step plan that we can start working on. Okay.
So, you can see uh ready to code. Here is Claude's plan. And we have kind of our full plan here. Looks pretty good.
You can see we have the implementation steps, build the YouTube client module, build the Gemini client module, data models, main orchestrator. Perfect. So, would you like to proceed? Yes, we are ready to write some code. So, I'm just going to let Cloud Code run in the background now. grab myself a coffee and I'll be back when yeah hopefully we have come quite far in our project here and it's nice to get this you updated to-do list here so yeah I'll be right back when cloud code has h done its to-do list okay so that was done that took only maybe a couple of minutes 2 3 minutes so we have our project ready so we can try this out but first let me tell you about today's sponsor and again it's going to be me so I have my AI video course if you're interested in diving deep into AI video generate maybe some small passive income or just have fun with the new models. So the AI video course uh I just added a new module. So if you go to my dashboard, if we go to courses, see we added a new module today. So this is going to be strategy for viral AI videos. If you want to create short form content maybe that can get thousands, hundred thousands, millions of views, this is a good module for you. So I just go through the things that has been working for me and how you can apply this to your workflow. So yeah, the AI videocourse.com if you want to dive deep into this very expansive uh niche that has created. So it's a lot of this content online now and I had a lot of fun with this. So yeah, check it out.
Link in the description. Let's go back to the project. Okay, so you can see the first thing we want to do is do a pip install requirements because we need those uh uh modules and libraries. So I'm just going to do that. Okay, so I did the pip install. That's fine. So the next step now is to configure our API keys in our ENV file. That should be ready to go. So I'm just going to do check my ENV files in root. So you can see we get back here and you can see your setup looks good. The project is ready to run. Now you can do python run analysis.py. So I think we're just going to do it here in cloud code now. So let's just run it because if we get any errors, we can kind of get that into context right away. Yes, we want to run this. Okay. So we have some small issues here. So let's see if we can fix that.
Yeah, there's import paths and stuff.
So, let's see if the clo code can correct itself here. Yeah, this looks much better. So, I'm just going to wait it out and let's see what kind of response we get back here. So, you can see we started the YouTube shorts analysis that's probably sending that over to Gemini. Okay, so that worked.
So, you can see now we extracted all the data to analysis results. And if we go into here, we find a URL for this video.
Good. We can zoom in a bit. Let's close that. And you can see we have all the information here. Here we have some tags and here we have all the scenes, right? So we have all the scenes. We have the AI prompts and everything we need. So now we are in theory we could recreate this. That's pretty good. So of course the next step now is going to be to create uh the images from this scene. So again I'm just going to go back to plan mode and I'm going to do this. Next step is to create the images from the scenes.
Uh I'm going to read some documentation.
Okay. and we're going to make the plan for this and hopefully this works out good. Okay. So, uh I want to change a bit here just for this video. So, uh just some inputs. We need to compress the scenes because the video clips will also be 5 seconds, right? So, we not we don't need 34 scenes. So, just for a test now, we're just going to recreate this short by using five scenes each on for 5 seconds, right? So, just for the video, we're going to keep it a bit compressed. But if you wanted to implement this, you could create up to 33 scenes. But that's just going to take a long time for the video. But uh let's just see what kind of plan we came up with here. Now, as you can see, we have our plan. So, uh now we're going to do se uh scene selection strategy. We have five different scenes. Yeah, I like that.
And yeah, I think we're just going to ready to code. Yes. So, let's go back to this and I'll take you back when we have the code for this. Okay. So, we are ready to test this now. So, I'm going just going to run this to see if the image generation is working. And yeah, hopefully we have the images when we get back get back. And from there, it should be pretty easy to generate the clips.
Okay, perfect. That was done. So, if we go to our images now, you can see we have image one, two, three, four, five.
Okay. Uh, yeah, that is working. Uh, so now we are just going to do some quick changes. So, I have one ID here. So let's just do we need to make sure that characters are coherent. So all descriptions should stay for all the for the same prompts for all the prompts. So we just need to update that and then I think our image generator is uh good to go and we can start doing the final part that is going to be the clips. Okay, good. So the final step now is just going to be to generate the clips. So we're going to we need a video prompt that will match each scene and we're going to send this prompt to the video generator model along with the image we generated for each uh scene. Right? So let's run that. Hopefully everything works out fine and we can test this out soon. Okay. So that was done. So now we are ready to test it. You can see ready to create viral short form content.
Perfect. So, uh, I'm going to add one more thing, and that is, uh, the styling of the overall video because we don't want to rip off exactly. We want to recreate kind of that video. So, I'm going to pick like an anime style just for testing. So, yeah, I'm going to change this to like an anime output instead of like uh whatever the video is. We're going to check out the video and we're going to compare it. So, yeah, let's give it a go. So, yeah, let's run it. So, the first thing we will do validate some API keys and hopefully we're going to find uh a new short form content and we're going to try to recreate that. So, I'm just going to let this run. It's probably going to take a while because we need to generate five five images, I think. I'm just going to take you back when we have the final videos. Okay. So, uh I stopped it here.
You can see now we have some clips here, right? Uh I didn't want to do the full scene. Uh, so I went ahead, I put these scenes we got here. These scenes from the short we picked out and I did some quick editing here. Just put it together with some music. Uh, but first, let's watch the original short that we tried to emulate. Remember, we added on this anime style here. Okay, so it was this one. Let's just watch a few seconds.
Yeah, there's a lot of cuts between the I guess the doctor and some patients here. Uh so let's see what uh when we took our scenes and put that together looks like. [Music] So yeah, that was not perfect, right? But you kind of get the idea. We could somewhat recreate the scenes that we saw in that short. And that was the kind of the idea here. So if you want this to be any good, we need to do do much more uh iteration on our project. But I think just the scenes we extracted for this could be valuable, right? You can see we have everything here. So yeah, we get some good valuable information from this if we wanted to expand more on this. But uh yeah, a lot of fun playing around with this automation project and it's getting better and better for each time I try to do this. So really exciting and I'll probably do a new version of this in like a few months, maybe 6 months, something like that. 2, 3 months, we'll see. And then we can kind of compare it to this one and see how far this has gotten. But uh most importantly, I hope this gave you some ideas what you can build. Uh so this video was just to show you what uh to give you some ideas what you can build by using these um pipelines you can create now using maybe cloud code cursor or you can just type it out yourself if you wanted to. But I really recommend cloud code or you can start off with Gemini CLI. I have a video on that if you're going to go check it out. Uh that's free for now. So you can start playing around with Gemini CLI if you like it. Then you could upgrade your cloud code and start diving into that if you want to yeah create more of this pipeline. So yeah, thank you for tuning in. Hope you enjoyed it and gave you some ideas and I'll see you again very soon. Don't forget to check out the link to my AI video course if you want to dive deeper in. See you soon.