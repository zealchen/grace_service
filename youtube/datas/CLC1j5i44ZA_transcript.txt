50% of white collar jobs over the next 5 years are going to be destroyed. That's just going to free up our time to go and do all of the work that we never got done before. What actually will happen is every company is going to take 2 3 5 10 years to deploy this technology.
We're either going to be managing the agents or reviewing the output of agents.
The AI agent is not here to help us be a little bit more productive. It's our job to make the AI agent productive.
A lot of our work is going to probably look like that in the future. And that's going to, you know, change almost every single thing about what work looks like.
That agent makes a mistake, a critical mistake. Where does the responsibility lie? It's going to lie in the human's hands.
All right, Aaron, thanks for joining me.
Hey, thanks for uh for having me slashwelcome to box.
Yeah, this is a great office. I'm excited to talk to you about AI agents. You are prolific on X, specifically about agents. Uh, so really excited to get your thoughts.
I, uh, I definitely have a weird obsession at this point. So, um, so this is what I spend most of my time on.
All right. So, I'm here at Box.
Yeah.
A few weeks ago, you put out a public memo. Box is a AI first company.
Yep.
I want to dig into that a little bit. What does that mean? And then kind of how are you transforming the company internally? So, first, what what does AI first mean to you? Yeah. I think um uh I think probably certainly anybody listening probably has a good a relatively good sense of of this at this point, but basically um it is a way of thinking about your operations and the way that that your company works in uh in effectively a fashion where you think through how can AI be applied to every task in the business to make the organization more productive and then ultimately drive more output as an organization. And I think a lot of companies have different kind of approaches that they take. Some will say we want to be AI first which is to you know effectively try and reduce the total amount of headcount you know applied to any given problem. I think that's a totally appropriate interesting approach. Our approach is a little bit different which is how do we actually uh just drive as much you know output as possible and use AI as effectively a capability expansion for the company.
So, how do we effectively just do way more than we ever could before? And um that can take on a variety of of things.
Obviously, AI coding is an easy one. So, how do we just build more features? Uh in marketing, it'll mean how do we either deploy more campaigns or tailor those campaigns to more markets. Um it should also mean that we reduce the time it takes to do any given task across the organization. So we have a lot of situations internally where we find ourselves saying okay you know the typical way that that project would have gone would be two weeks but actually we don't want to take two weeks anymore on on that we why can't we do that in two days and so we're constantly thinking through how do we work way faster uh as an organization uh with the use of AI so that could be everything from generating content generating code deep research on different activities um being able to do you know frontline customer support how do we enable our sales reps with better AI kind of across the board.
Yeah. What I mean all these tools are so raw.
They're so new right now. There's a lot of edge cases which aren't even possible. How are you playing around with the new tools and deploying them internally? And I I do want to get to like headcount and how you're thinking about growth of the business. We're going to come back to that in a second, but yeah, how how are you playing around with the tools? How are you experimenting? Do you have a team dedicated to that? So, a couple different things. um we have a little bit of a group at the executive team that that is sort of constantly figuring out where can we go and and kind of you know point all of our strategic effort across the organization. And so um that that's sort of you know I I hate to call it kind of a council. It's just a it's a group of us that is you know constantly meeting figuring out where we can go apply AI. Um, we have by virtue of being box, we have AI products internally that we've built. And so a lot of what we use is Box AI to generate as much productivity as possible. And so the examples are are pretty straightforward.
I'm a sales rep. I'm coming into the company for the first time. I want to learn like what's the best way to pitch a customer on a product. Well, we have Box AI on this product called Box Hubs that looks across all of the knowledge related to sales or marketing and then lets you ask questions of that data. So we're enabling a lot of the AI use just within our own product. And then um we're encouraging as much experimentation of approved platforms as possible. So um you know we'll have teams go off and and try a bunch of stuff with cursor and then share those experiences with other teams. So we want is we want to balance sort of a little bit of a top- down directive that says okay let's use AI in more places with more of a decentralized approach that basically understands that we're never going to be able to predict and advance all of the great use cases that are out there. So we want people experimenting as much as possible within the guard rails of okay systems we trust where there's no training on customer data where we know that it's it's going to be you know people accessing data they have access to. Um and then the only other kind of final point is we're trying to get the best practices to be shared as much as possible internally. So we do things like once a week we have an internal all hands where everybody gets on on a video call and one of the sessions now in that all hands is somebody uh anybody from the business showing off how they're using AI uh within uh within their workflow. And so every week you're going to get a demo internally of of some team using AI building an agent to automate something.
So we want there to be as much sort of you know effectively organic creation of these ideas as possible as muching you know within the organization as possible and experimentation as possible and and I believe I remember in the memo you're saying you want your team to do a lot more with the tools that they have and so how do you encourage them what are the incentives to help the teams kind of embrace AI embrace AI tools rather than thinking okay who else can I bring on what else can I buy you know yeah I I mean, we're we're we kind of get to do this a little bit on easy mode relative to most organizations. Um, by virtue of being a software company in the AI space in the middle of Silicon Valley, it means that demographically a lot of the box employees or boxers are already kind of wired to like how do we get as much innovation as possible in how we work.
So like I I totally have a lot of sympathy for you know people outside of software just trying to navigate this because you also then have to just do basic you know training of like what's going on in the AI space you know in the first place. So for us we we already start with a little bit of a of a head start that that's a little bit of an unfair advantage. Um but then you do have to make sure that you're you're contemplating okay where are the natural points of resistance in an AI roll out.
Well, one would be okay, if I deploy AI, like is is is your goal just to then go and automate my job away and then do I have a job at the other end of that? So, one thing we've just been, you know, we try to be unbelievably explicit about is our goal is to do more as a company and to arm every single employee to be able to do more. We're not looking at like particular functions with one exception.
Um, we're not looking at functions and saying, "Okay, let's go re, you know, sort of completely shift that that that sort of, you know, function." The one area that that I think we've probably leaned in the most and said, "Okay, we think that, you know, if we can deflect more and more inbound, let's say customer support cases, what we can go do is actually, you know, create a better experience for our customers, but also redeploy that same set of resources, either the actual people or the dollars into things like proactive customer success. So one thing that that you know I think helps with uh a roll out is is you know and and maybe maybe the inverse first the mistake that some companies make is to say you know go use AI and where you can't use AI that's where we're going to add headcount to the organization. I I generally think you want to kind of do the opposite where you basically say the parts of the organization that are using AI will be the ones that get more budget and and you want to find ways to effectively incentivize or encourage the use of AI across the organization as and and one of the mechanisms is to say okay if you can actually make your organization more efficient you'll probably be higher on the list of the teams that get the next set of headcount or the next set of budget to go deploy against problems.
And so the more you can kind of create these virtual, you know, virtuous flywheels or cycles um around adoption, better productivity, more budget and and so on, that I think will will lead to a lot more uh you know, feeling of of safety and comfort as you go and deploy these solutions. Yeah. I always curious why people think, okay, how do we just automate away X job, Y? But really, if you're able to get so much more productivity out of every employee, why don't you go tackle new use cases? There's a lot of market out there. there's a lot of problems that haven't even been the economics weren't viable quite yet. So, I I appreciate how you're thinking about that.
Well, I think the good news um for let's say, you know, kind of anybody, you know, in in doing some of these jobs that that maybe, you know, you sort of see, okay, well, am I trying to be automated, you know, way or whatnot. Um the companies that uh treat AI in a very myopic way and you only go after cost cutting, we're all in competitive industries. There's very few companies that do not have a high degree of competition. And so for every company that decides that they're going to use AI, let's say to reduce expenses, there'll be another company that says, "We're going to use AI to do more." And the company that can better serve their customers with AI will be the ones that get more customers and and higher satisfaction ratings and better products and services delivered. And then those will people will be the ones that go and hire more people and and grow the functions that are that are, you know, getting higher productivity gains. So I think it's a very temporary phenomenon where you would see even a reduction due to AI because the talent would then just flow into the areas of the economy where people are seeing productivity gains and then reinvesting. So one example would be my my hunch is in three or five or 10 years the size of a small business in terms of headcount coincidentally will be higher because what will happen is high small businesses will be able to actually do more right out of the gate as a small business which then encourages them to go and build up all of the adjacent functions based on the areas where they've grown. So great example is, you know, one of the classic problems if you're a two, three, five, 10 person company, every single new hire that you bring on could be like 10 to 20% of your total expense envelope, right? But like just if I have one person, I only have 10. I've just literally grown my entire expense envelope by 10%. Let's just say there's a lot of activities inside your business where you can't justify growing your entire budget by 10% just to get going with a new marketing campaign, a feature you want to, you know, create, bugs, you want to go and close. So what happens is those companies just never get around to that work. Well, now in a world of AI agents, they start to go do that work for you. And then what happens? You build a better product, let's say, or you serve your customers faster. The next set of things you're going to need is maybe more sales reps to go and then talk to those customers that you've just now increased your your kind of, you know, effectiveness in going and serving. And so what will happen is you'll actually get bigger faster as a small business than you would have preai simply because you never would have invested in the functions that could have let you grow faster because just like there's only a small amount of percent there's only a small percentage of SMBs on the planet that take venture capital let's say so most SMBs are constrained by their access to capital resources talent in their particular domain and agents basically you know goes and explodes that okay let's continue on that Dariamay Okay, I'm sure you saw Anthropic CEO said I have I have some disagreements with this.
I'm sure you do. White collar blood bath. 50% of white collar jobs over the next 5 years are going to be destroyed.
Um Andy Jasse, Amazon CEO, just said they're going to be reducing corporate headcount uh because of AI's productivity. You have a very different approach. I tend to actually agree with you, but what are they getting wrong? It's both I respect both of those those uh those people. So um so I think my point of view would be let's just parse the two differently because it's actually represents different concepts. Daario's point I think is like a super interesting thought experiment which is at the pace of AI agents um uh you know what would happen in a vacuum if agents you know if you extrapolate what agents do from here to 5 years from now I think like in a purely academic sense he's probably correct which is which is agents will be able to do many many of the many of these jobs. I think the the real life experience though will end up being different because what I tend to think happens and and um just as a counterpoint, Alex Wang was recently on the the YC podcast that I think articulated this best, which is which is there's this longtail, I don't know if you said long tale, but there's this work that that basically agents continue to fail at. And it's like that last it's that last mile. It's the last mile of autonomous driving. It's the last mile of agent work, which is the human does have to review the work. the human does have to orchestrate what the agents are doing. The the human does have to kind of incorporate all of the the output from the agents and so I don't think that goes anywhere even as you get you know orders of magnitude improvement of of agent effect effectiveness because that's just a moving you know basically goalpost of then what the humans end up doing with those agents. That's the first thing. Second is I think there's a lot of stuff that we do that just simply will not be able to be replicated by the agent. It's not the kind of stuff that you send off as a blackbox task to come back with work. It's the personal interaction that you have to go and do to be able to produce value in the economy. It's the sales rep talking to the customer to go and coordinate, you know, work uh that needs to get done or a deal to get done. It's the, you know, lawyers talking together to negotiate, you know, a deal or a case. So all of that work I think we underestimate how much of that both exists but also how much of that will exist in a world where we don't have to now do all of the drudgery work. So think about a world where we have agents running around handling all the more let's say menial tasks that we don't want to do with computers. That's just going to free up our time to go and do all of the work that we never got done before. Um there's a uh um uh sort of a kind of a fallacy or paradox called lump of labor um fallacy which is basically this this idea that we kind of assume that like we happen to be like we have the right level of employment relative to the amount of demand for services at any given time in the economy and um and that sort of under anticipates just like you know any kind of you know shift in efficiency which then not to like really get super you know uh geeky but like then you add in like Jevans you know paradox let's So if I can bring down if I can increase the efficiency of a particular category of work, let's say legal work or healthare or education or sales. The question is is the demand for that set of services greater than the efficiency gain that was caused. And I think there's a lot of categories of work where that's the case where if I can make it way more efficient to do a marketing campaign, I will get more than a commensurate amount of demand for marketing labor to go and create those campaigns or for legal work or healthcare and so on. And so the thing that Daario's point doesn't anticipate is actually do we do we end up seeing a Jevans paradox for labor because AI has now made it way more efficient to get output from that labor that we would not have in a vacuum been able to predict. I made a video specifically about this and I proposed that yes, it's kind of like Jevon's paradox. As productivity increases, as productivity per employee increases, we're going to be able to do so much more.
Yeah. A lot of the push back I got was maybe there isn't so much demand. Yeah. And how does demand scale with the more supply of solutions you can bring to market? Yeah. I I mean it's sort of um uh you know without the without that counterpoint person right here, it's sort of hard to argue. I would just say they're wrong. Um the because um partly because it's unknowable on both sides. So so my opinion is just that that we actually could have substantially more demand.
I'll give you a couple examples. Um I don't know if the last time you've been to a healthcare provider um but uh my personal experience is that um when I call doctors of different kind of topics and you say okay when's the next time you can see me and they probably somewhere say between two and six months depending on the topic.
So like to me that's an instant and obvious sort of example of like the fact that I can't see a doctor for basically any given topic next week on just like instantly on demand. We are probably off by the number of health care providers by two to threex would be like my just like quick hunch. So what's happening? Why are those doctors not able to serve clients? Well, there's a lot of administrative work that they have to do. There's they they type in, you know, all the notes from each visit that they have to do. So, okay, could AI shrink that by 30%, let's say. Could AI make all the back office operations so much faster? you probably still then as a result of that would need to then flood even more you know actually doctors or physicians or you know nurses in the system as a result of that efficiency.
So that's healthcare maybe that was an easy one. Um I I have uh I have a friend who has a Shopify uh uh company and it sells balloons online and so uh his his business is he has a website and it sells balloons. Pretty pretty actually successful and and I you know probe all the time like hey would this idea you know work for marketing? and we kind of go back and forth and I'm just going to make a hunch and maybe he'll like respond in the comments that that it's not accurate. But like if he could press a button and say, "Okay, do all my marketing for me, do all my Facebook ads for me, do all my SEM, uh, you know, for me, do all my inventory for me, uh, could he imagine a world where he gets more customers and thus would then hire more people to do supply chains and to do product development and then engineer the product better?" I think the answer would be yes. he's always constrained by his ability to go deploy all of those things for either his own time or his, you know, limited team's time. So I just don't think there's any sort of cap on the economy of the amount of demand for so many different categories of service that when we bring AI into and it makes that more efficient um your ability then see those categories grow as a result.
Yeah, I think healthcare is actually a great example. Um there's probably not only the delay between when you want to go see a doctor and when you actually get the appointment, but I think there's probably people who are just not willing to wait at all. Yeah.
Right. Or or they they would ask questions to a doctor more frequently for smaller problems.
There's this entire I'm going to use the word long tail of of health concerns that AI could facilitate. So okay. Well and and just even one more example. So listen at at box if we you know we look at AI every AI tool possible to make us more productive and so like let's say one category is if we can make our sales reps 10% more productive you know classic uh stat in and you know doing any kind of B2B is is sales productivity which is basically the amount of sales you're bringing in relative to the to the spend on that sales rep. Let's say if we could add 10% productivity, so you're getting 10% more dollars uh from a from a sales standpoint, you have you have two options. One, you could just be like really happy that you got the 10% more dollars and move on with your life and now your revenue grows, let's just say. The other scenario is you're really happy and all of a sudden your sales rep sort of budget allocation process becomes a more attractive thing to put dollars into. And in our organization at least based on how big we believe our market opportunity is, we will just go and put dollars back into sales the moment we can drive productivity gains.
And I think there's a lot of functions in most businesses where you have a particular um there's a particular uh you know slowdown in some in you know you know some part of the organization and if I could make that more efficient we would actually then go and hire either in that direct function or in you know corresponding roles that are tied to that function and that that I think is most of the work that we're doing.
Let's talk about what work will look like for humans in the future.
You know there's there's kind of two paths. we're either going to be managing the agents or reviewing the output of agents. Like maybe it's a spectrum. Where what's your what's your thoughts on that? Where where do we kind of skew? Well, this is the this is kind of the most fun one I think at this moment in where AI is to try and explore is what is the future of software and then by extension you know what work looks like. So recently I've my mental model has been I think most of enterprise software it basically is to digitize and enable the way that we do our work right so so so what do we do all day right we we go to a computer if you're knowledge worker and you type a bunch of stuff and you're in meetings and you and you're coordinating things and you brainstorm but you know a lot of the output a lot of the things that we end up monetizing is happening on that computer and it's happening at the speed at which you personally can do something the speed at which you can research something the speed at which you can write code, the speed at which you can design a marketing asset. And so the company is basically moving at the rate at which you're able to produce something on a computer again in a in a fashion that is coordinated with other internal or external, you know, kind of individuals. So now add a AI agents into the picture. Those AI agents, you know, I think two years ago, we would have thought those AI agents will we didn't we didn't call them agents, but the AI systems will make what you're doing way faster. So you're writing code and it's typing ahead and it's autocompleting the code you want to write and like wow all of a sudden you're writing 30% you know more code because this thing is sort of this extra uh you know accelerant to your work and that was our mental model was like okay well now I could write a report and it's probably going to help me type you know couple sentences or a paragraph at a time or I'm um you know responding to a customer and it's going to auto inject the right response to give that customer and so that was our mental model for the past you probably year and a half post the chatbt moment was this stuff is really about creating text or images on behalf of the work that we're doing as we're doing that work. Turned out that was wrong. The the right mental model is wait a second these things the AI agent is not here to help us be a little bit more productive where it's like totally inverted. It's And the AI agent is not bound by any capacity constraint in you know how quickly they can type or the hours of the day that they can work or the number of computers that they can access or the number of places they can be at once.
And so in that world everything flips on its head, right? So enterprise software as an example needs to be designed to effectively make it so you are man you're using that software to plan what the AI agent should do to uh create the tasks of what it should be working on to review the ultimate output uh that it comes up with to orchestrate and then integrate that work into some bigger picture thing that you're trying to do and so if you know I because we're in B2B enterprise software I sort of think of work and software in one and the same so that's what software will designed to do. And so thus I think that's a lot of what our work will be. Our work will be thinking about what should I deploy to the AI agent. You know, how clear are my instructions? What is the what is the bigger picture thing I'm trying to do? And then how do I, you know, give it a granular enough task that it will be successful but not so granular that I'm not, you know, getting any kind of real productivity gain. And then how do I make sure that's the type of task that I can go and incorporate into something else. So you know the best examples recently are things like you know AI coding. So um I was uh I was walking by an engineer you know a couple days ago within box and he's using cursor and I said you know how do you how do you use cursor differently than let's say GitHub two years ago you know copilot two years ago and it's a pretty fundamental difference right it's no longer that the AI is sort of typing ahead as you're writing code you know he he goes and and and asks the agent to go and create something it creates it and then he's spending his time reviewing the code of the agent and he basically says that you know it's he's always finding something that it did wrong and we know why. It's like these things are probabilistic systems. So, but it literally means he's producing 50% more output because instead of him having to look up every single class and function and and learn that particular, you know, part of the code, um the agent is going and doing that and he can way better spot what the agent did wrong than the accelerant of just it typing ahead of him a little bit faster. So, think about that for basically all work. And that was why I got excited about things like let's say codeex because codeex is like almost the ultimate manifestation of this right it's a it's a task cue for agent deployment right it's not attempting to be your code editor it's like I go to a thing and I ask it to build something goes off works for 10 minutes I go and check and and you know go through the diffs and I look through it and review the code like that is probably how a lot of agentic systems will manifest over time is you get a task system you get a prompt prompt. You you prompt it, it goes off, does you know the equivalent of tens or hundreds of hours of work in a few minutes. You go then review what it did. You grab a chunk of it, you incorporate it into something else. And so a lot of our work is going to probably look like that in the future.
And that's going to, you know, change almost every single thing about what works like looks like. Are you using codeex at the is box using codecs, I should say? Um I I'm sure some engineers are. Right now we've been more in the kind of cursor deployment mode. Um but uh but I I don't know the official deployment of codeex right now but we we love you know chat GVD products.
As a company like Box becomes more productive as like Google and all of these companies become insanely insanely productive. Do you see any risk of a concentration of power amongst a very few amount of companies because really the only constraint seems to be capital in the future if knowledge the cost of knowledge work approaches zero. Is there a concentration of power risk there? there is um it's kind of a trajectory that we've already been on. So I I don't I don't I mean I probably should be more worried about it. Um but it doesn't feel any different than the path that we've been on. And I think um I you know I think we're in this really fun mode where a brand new startup and we've seen this with cursor and you know many AI startups a brand new startup wind surf replet etc with a tenth of the number of engineers or or let's say employees previously could get to the same level of revenue. That's insane. that like you know blows my mind, right? Um and so at the same time where the biggest companies now have have the compute, they have the infrastructure, they have nearly unlimited budget to go deploy it, we see small startups that are outgunning those big companies because they've nailed the right innovation um at the right time for the user experience. Distribution has come down uh from a from a cost standpoint because everybody's on the internet. And so I like I actually like the startup's odds as well at this moment. And so I I go I'm you know pretty schizophrenic about this topic which is which I I think it's a great time to be incumbent. It's a great time to be a startup. It's just basically an incredible time to be using technology.
Yeah. And so you kind of see it as the same dynamic as it's always been. There's there can be a startup that can go challenge that massive company because they have better taste on how they're putting the experience together. They have some some insight that maybe was was overlooked by that that large company.
I think you're basically you have to choose your markets wisely, right? So, it's probably a very bad time to build a horizontal personal assistant chatbot, right, as a new entry because I think that game is like, you know, we're kind of have seen the the we we've seen the contours of the of the, you know, competitive map a bit. Um, you know, you wouldn't want to lodge like no social network worked, you know, six months after Facebook for at least, you know, 10 years until Tik Tok, let's say, because because it was like that was the game and so Facebook was the play. ChadBt, you know, Grock, Gemini, Claude, like like we we we've got the we got the, you know, City, we have the players on the map. There's probably not new players in that space, but man, I can think of more spaces today that are now up for grabs for startups than in the past decade of being in software. Like there's this um I was thinking the other day about this kind of example of you know we had like 2008 to 2014 making up a rough time period where like you know Uber, Instacart, Door Dash, Airbnb you know every one of these companies just got created and it basically satisfied you know most of our core consumer needs like you know travel, food, transportation, music. We we got we had like we covered all of the bases in that window. And then if you miss that window, it's it was kind of like not a really interesting period for for quite some time on the consumer space. AI is kind of a reset of that which is for consumer and B2B. And it's basically because we we now have for the first time a set of categories that previously were never digitized that now AI agents can go and get deployed into.
What's an example of that? kind of everything like every category of professional services.
Yeah. Like the the category for software for lawyers or the legal industry has been one of the smallest software categories like in history.
Harvey just raised a bunch, right? And and so like Har like just here's an example.
Harvey's market cap is bigger than the entire category of software sort of spend for contract management systems in history. And it's because like lawyers are like, well, we'll just email documents back and forth and we'll review the contracts and we don't need a lot of software to go kind of work on that problem. And all of a sudden, AI agents now is the first time that that industry will be will be digitized in a meaningful way. You can go category by category, you know, healthcare, education, tutoring, um, life sciences, drug discovery. There's so many spaces that we we really never were able to fully digitize that AI now creates markets for. And guess what? If you couldn't have digitized that industry previously, it means there's not a natural incumbent that is just kind of capturing all that market, which means it's up for grabs uh for startups. Now, there'll be incumbents that sort of are adjacent to that that area of work and that they can enter with agents and we're going to do that in a number of spaces, let's say. But there's also a great opportunity where because there's no natural incumbent, some new startup will have the right message at the right time with the right distribution and there's plenty of opportunity for them.
And that's why I'm not overly worried about the hyperscalers and and you know just the fact that there's okay maybe five or six you know AI models. I think there's so much work to be done on top of the models that that becomes interesting.
Yeah. I totally agree. I say often scaffolding is really where the investment needs to be right now.
Yeah. Yeah. 100%.
Yeah. Okay. So I want to and obviously I'm extremely biased but but we uh we are we think there's a ton of opportunity there.
Yeah. Um, and I'm going to get to box being model agnostic, AI agnostic in a second, but I want to just touch on something that I get asked pretty frequently, personal versus work agent. So for me, I I, you know, built up this long history with Chad GBT with with Claude. I mean, Cha GBT really has amazing memory. Memory as the kind of feature is is incredible.
And I'm thinking where where is that delineation between my personal agent and the work agent? Because I feel like if I have this personal agent that has developed a shortorthhand with me that knows me, knows what I want to do and then I bring that to work, that could be incredible. But then of course there's all these IP issues and Yeah. Okay.
Thought about this.
Yeah. No. Well, well, I mean it's it's uh memory is going to be one of the funniest, you know, technical problems because um so I can't even contemplate the the combination of personal memory uh into this like even even just like even the personal memory in the personal staying in the personal domain is a hard enough problem. Uh injecting the personal memory into your corporate kind of AI agent system is like that's that's going to be you know that'll be some interesting you know kind of questions.
Um you can instantly think of all the problems right? So if I have a lot of personal health stuff that I'm you know doing with an AI system uh and then I bring that into a corporate environment all of a sudden you know and that that sort of influences in some unknown way some set of decisions or things that are going on um you know unbeknownst to me that that's going to be a huge problem.
So I don't I don't I think you're going to need church and state between the personal side and the and the corporate side which will mean that you maybe don't ever fully maximize the benefits of AI uh kind of memory. uh but you probably have to make some trade-off on kind of like appropriateness and ability to govern these things versus the full maximum value. Even on the personal side, you run into this tricky thing which is like sometimes I have a lot of conversations with an AI system that are totally hypothetical or not even about me. Um, and you don't necessarily want the AI getting confused that those are like important things to remember or attributes like and so you know you you you have this balance of like some things I I definitely want to be reinccorporated and and I wanted to know about for future questions and then other things are like that was a weird temporary period that lasted you know a week and I I don't need you to you know I don't need you to remember remember that or think that that's some kind of ongoing you know problem I'm dealing with or thinking about. You know, these are the these are the things again where when we anthropomorphize AI, we're gonna we're gonna get some of these things wrong as a human. You know, while obviously that's like in our brain somewhere, we tend to be able to be like, okay, I'm just like not factoring that in because I know that that that part of the embedding space is just totally irrelevant to this answer I'm giving. The AI model is is going to be a lot harder for the AI to to know when to incorporate those, you know, that part of the context window and when not. So I'm I'm very curious how that's going to work. And then you also have this issue of memor memory portability um which is which is going to be another problem which is okay if I do years and years of interaction with chatbt and I have no ability to you know make that portable with Gemini or Enthropic you know how am I going to feel about that in the future? Yeah absolutely big questions.
Um so I think it would be fun as an industry if we had a standardized you know you know context window insert that was that was sort of like okay here's a bunch of knowledge. Um, it's like my personal card of data that I give to AI systems. Um, I maybe maybe somebody could, you know, start to create a spec on that and and we'd all support it.
It feels very similar to what MCP did, right, for for agent tools. It it just feels like there should be an open standard for agent memory where you I'm specifically talking about personal memory, right? So you can go from Google, you can go to OpenAI, you can go to Microsoft.
And then there's, you know, obviously I want to talk about the context of enterprise with memory.
So let's stay within the full context of enterprise. I worked for Box for 5 years. I build up this memory. Then I leave the memory IP of box. It stays with I go somewhere else and I start to have to develop that entire thing again.
It seems like you're it's like completely starting from scratch.
It is there something you could envision box doing when you hire an employee from somewhere else to help onboard them more quickly to the agent? It's really that that employees agent. What What does that look like? I I mean now we're just brainstorming in real time. So um so we have like breaking you know spec news uh on this on this podcast. Um I think it's a very cool idea. I mean, I think I think you could imagine a um you know, you could imagine a file that is sort of like your like agent resume, but like on on crack, which is just like here's a you know, 30, you know, 20 page document that just knows every single thing about me, how I work, you know, the the kind of, you know, style of text that I work in. I'm in marketing. And that would be personal.
And that'd be personal. And but again, we're just brainstorming. But like I see no reason why why again some kind of agentic memory that that you you get as a right of an employee or a citizen or in a healthcare provider. I I think that's super relevant. You know in there's an interesting kind of analogous uh thing that was was attempted in healthcare um under the Obama administration sort of your ability to get your you know access to your medical records was like a fairly big thing. The challenge was it was so unusable that basically no consumer has ever really been able to interact with these things.
So you'd have to solve this issue which is like for us and for you know anybody listening like yeah sure we'd love a portable you know JSON you know you know uh file that has our our AI memory but like for our parents like okay how are they ever going to actually you know be able to pull that off but I think it makes sense and you know hopefully the industry supports things like this over time. Yeah, I want to I want to talk about responsibility, agent responsibility specifically. Agents are non-deterministic. They're probabilistic as you said. They can make mistakes.
They do make mistakes, especially now.
They're going to get better. If I am an employee and I'm deploying agents and that agent makes a mistake, a critical mistake, where does the responsibility lie? And and how do you manage that? I mean, for the foreseeable future, it's going to lie in the human's hands.
There's just no way there's no way around that because there's no agentic system that is that is good enough that you could basically kind of go on full autopilot and just say we are fine with that thing making all the decisions b you know until you are fine with the AI making a a final you know key decision it means that this the system is not good enough to remove the human in the loop at some part or in some degree of granularity in that in that workflow and so I think most companies that have deployed AI at this point are basically saying, "Listen, you should use AI. You are still responsible for the the thing that the AI is producing. You need to review the code. You need to review the legal document. You need to review the email that you're about to send to the customer." That's on you. People are going to go through, you know, some awkward phase of like they'll see examples where the human didn't actually review it and they get back some, you know, gibberish thing and then, you know, that person will need to be, you know, talked to and there'll be some kind of training session on that. We're going to be in that phase for a while. couple years, five, three, five years.
At some point there's a hands-off the wheel moment for some scale of workflow, right? And that that is we have not seen a lot of systems that are ready for that or a lot of workflows that are ready for that. But when that happens, then actually there's a new era of responsibility or governance or liability that will have to emerge. You know, right now Box as a platform is liable for a number of categories of events that might happen in our system if a customer experiences those events.
And there might be a future state where you will have that level of reliability also on an AI model provider or on an AI system provider. We're not there yet because again of how fast these are these space the space is moving and where the models are. Um but I think in three or five or 10 years from now if I go to a vendor and I say I want you to create an AI that writes an application for me. If I have no ability to look into the black box of what that is doing, then I need to be able to hold somebody responsible for when that thing produces a bug. And so at some end state, I think this will this will be appropriate to hold the provider responsible.
Well, with lack of a very strong set of guard rails for this for these AI systems and and you're an you know, imagine you're an employee at a company, you're probably going to be very cautious about about deploying them. And is isn't that going to slow down innovation? But I guess maybe that's the necessary thing for you know especially a company like AOX where you're dealing with critical elements of a company system.
I think the thing that we the the one part that we definitely get wrong and actually maybe back tying back to Daria's point um the the thing that I think we tend to get wrong is we are all in the trenches seeing this technology and our minds are blown about what it's possible of and we can extrapolate about what what's possible in the future. It turns out like when technology hits the real world, the amount of change management you need to actually incorporate this stuff into the work that we're doing is like two orders of magnitude more than we realize. And so this is also why again the five-year the five-year kind of analogy or or five-year claim from Daario I think is wrong is is like is like that assumes this kind of overnight access to this technology that gets disseminated in an even way faster than the company's ability to go and respond and use it for productivity gains or growth. then it's just pure cost cutting. What actually will happen is every company is going to take 2 3 5 10 years to deploy this technology and even then they'll still be going through various workflows where AI will will emerge later in that workflow. We are now somewhere between 18 19 years into the cloud boom like if you just kind of mark it as let's say the launch of AWS and these companies are still growing at double digit percentage rates which is basically definitionally means that most of the market has not fully been captured yet that there's still this incredible space out there that people are onre I talked to before before this podcast I talked to a company that their data is in on premises fileshares that's where their file files are being stored 20 years into the cloud movement and that is like not a small number of those companies.
So imagine doing this podcast in 2045 about AI and having that exact same kind of correlary between cloud and AI. We would be talking about it as if it's still this thing that companies are still adopting and doing the change management around. That's how long technology takes to roll out. And so does this not feel faster? AI does it not feel fast? way. It's way faster. But but again, what's interesting is that is that even in an organization where AI fully rolls out to everybody, what happens is our work just shifts upward.
Let's say now we're deploying more, you know, to to the AI systems that will become that will just then feel like normal work and and then and then there'll be another wave of AI that comes and makes that work more automated and we will just constantly be doing that. Um and so this space is absolutely moving way faster than cloud ever did.
So let's say you can compress it by 2x, right? So maybe this podcast in 10 years is is more appropriate. But the change management of humans is is your ultimate the ultimate problem. It's not the speed of the technology innovation. It's the speed at which a person can go okay like a month ago I went to chatbt and I asked this question and it and like the answer was okay I got to check back in to see if the answer is better. Oh, it's better. Now, how do I incorporate this in my workflow? And I got to wire that up and now I have to do some automation thing where I build an agent. Like that is that has to happen billions and billions of times through the economy for all of this productivity gain to actually get realized within within the economy. That's just going to take years no matter what.
One more question about agents. I'm sure we're going to come back to it, but there seems to be three groups of folks building agents. There are SAS companies like yourself. There are model providers like OpenAI. And then there are agentic frameworks like crew and lang chain. Who who is ultimately going to own the agents at the end of the day? Um is are you allowing for basically no answer? Um or all the above? I I think I need I think I need an all the above answer. I think that, you know, I used to um I used to think in these sort of zero sum ways. Um like when when the cloud wave was first starting, like the mindset was like, oh my god, Amazon will just have all the world's compute and like CRM like Salesforce have like all the world's CRM and there'll be like five or seven providers cuz like how much enterprise software do you actually need? Like you only need like 10 apps. Fast forward again nearly 20 years later, there's four or five big hyperscalers that are all tens of billions of dollars of of revenue. There are, you know, I'm going to make up a number, hundreds of companies in the let's say 500 million in revenue and above range or at least few hundred million in revenue and above range. How did that happen? Why wasn't it a winner take all market where like you got all of your SAS from three or four vendors and all of your compute from one or two providers? It's because basically like the world wants choice.
Uh for every horizontal player there's a vertical player. For every centralized player there's a best of breed network of players. Um we are all doing yin-yangs on on somebody else's strategy to serve a part of the market that you know previously was was under uh you know kind of exploited or solved.
AI agents will will have the exact same thing play out which is there'll be some from the model providers that are really good at a few core things. every SAS vendor will have, you know, n number of agents tied to their particular products. There'll be other new AI agent infrastructure companies as you mentioned. And I think, you know, probably all this points to is the need for more interoperability, more standards, more ways that agents can kind of talk to each other and and coordinate work, which is why we're extremely big on the ADA protocol that Google launched, MCP from Enthropic. um anything that can create you know ways of handing off work between agents or better ways of of them talking to each other is is you know in our in our view very very good okay so let's let's continue down that path I want to talk about the future of SAS Nadella uh CEO of Microsoft said the the application layer is going to collapse down into agents y first of all what are your thoughts on that specific quote and then also like how are you thinking about the the vision of where box can go when agents start to consume more and more of the application layer yeah so si uh that that went very viral. Uh every every B2B founder on the planet was like either freaking out or pissed off or some reaction. Um but you know he he provoked a good a good energy in the ecosystem. I think that it's um first of all I think it's super provocative. I like it as a brainstorm kind of idea of like okay do I go and talk to agents for all of the things that I want to do as a result of that? Obviously that abstracts away a lot of the a lot of the value that was created in the kind of guey and UX layer that that so much of our energy has been put into and it really you know does reduce you down to some extent as a database permissions structure workflow system which obviously would mean you know less economics flow to that part of the stack over time. So you have like that as a as a vector. So you you kind of brainstorm that. Then you have this counterpoint which is okay, you know, but but like users actually like when you do something two or three or five or 10 times like actually you don't want to go reprompt an AI system every single time for that. Like that's like you kind of want to go to a thing that has buttons or graphs or tables or or dashboards. Like that's what a lot of software has helped represent like what's going on. And again, you don't want to like every day reprompt an AI agent like tell me today's, you know, revenue just like that's like why like God invented dashboards like like it's just like a solved problem. So, so I don't know that everything gets subsumed by the agent from a UX standpoint. I think agents are running in all of these systems everywhere 247. And I think that actually interestingly and I don't think Sati would disagree with this. I think the SAS platforms are are basically in the most natural prime position to being to be deploying AI agents within the context of their particular domain. And so that's sort of why I don't think that that these systems get abstracted in a economically disadvantageous way because if I want to go have an agent answer ITSM questions, deploying that in service now is sort of the logical way to do that. If I want an agent to help my sales team answer customer support questions or customer, you know, sales questions, agent force at Salesforce is sort of the natural way to do that. If I want an agent to run across all my documents at Box, like just having an agent that deeply understands the box workflows and context is probably the better way to do that. So I think that actually makes the SAS systems more valuable. One byproduct of of the era in which we all got created and scaled was web services APIs were like by default the way that you built SAS products like you have a UI and you have an API which meant that we're all primed for a world where agents can run you know with tool use and run through these systems is basically these kind of super users and so and so you you have this kind of you know basically perfect set of ingredients for agents to to be deployed within SAS and then I think to Satia's point where again I I'm I'm I'm I would agree with him is those agents then get coordinated maybe in some rollup point within a chat or a claude or a agent space or a co-pilot where they're doing work together in the background and then I might as a user interact through a chat system but I actually still need agents that deeply understand the context of that particular software environment to create value for me. But aren't agents going to actually write that deterministic part of the UI layer? And depending on what you need as a user, you can prompt once to that agent.
Yeah, the agent will start to predict what you need and maybe will write the deterministic code for you so you don't need to rep.
I think it's I think it's possible. I think the um I think the thing though is like probably most users don't want to do that.
Yeah. Um, I think that the um I'm like extremely bullish on on the essence of vibe coding in the sense of like wow like the agent like wrote all this code for me and it like works. I'm very bullish on that but with a with a massive nuance. I'm bullish on it for the IT person that's like okay there's this app that the team has always wanted me to go create and like finally I can get around to creating it.
I'm not bullish on it as like like Bob in finance is just like I'm gonna go and like like create custom code for my close of books end of quarter process.
Like that's just something where like Bob doesn't want the liability or the risk or like try like he doesn't want to have to understand like did it work or did it not work. He just wants a vendor that's just like it's really good financial software that solves his problem for him. When the auditor comes he's like yeah it was those people. it wasn't my agent code. Like that's what Bob wants. So I think that the these markets are going to be insanely large because actually I think the world needs about 100 times more software that's different from every person on the plan is going to go and custom code every piece of enterprise software that they interact with because I just don't think they I don't think that's what we want to do at work, you know, all day long.
Yeah. I want to talk about the future of the web with you.
You talked about APIs, especially like when you're building a SAS company, you build the the UI and then you build the APIs and and you expose the API so people can developers can build on top of you. There have been a lot of browser use frameworks out there for agents.
Do you foresee that as the end state or is it more likely that we're going to have APIs for everything so agents can browse the web more akin to what they're used to? Um yeah, I think this is uh this is probably just another one of those categories which is which is these last mile questions, right? So I think that this will cause you know a you know 5x or 10x increase in API creation as well as the the ability to describe uh you know the either the APIs or the software to the agent and there will always be this long tale of things which is just like even if your API was perfect there for some reason there's some kind of task coordination between multiple systems or there's some scraping step that I got to pull something from one UI to another and the API design is just never you know that clean for that particular you know pattern of work and so I think that that I'm I'm bullish on both the increase of APIs and the increase of browser use by agents um I think there's uh I was playing around with operator when it launched and there were lots of use cases that actually no API in the world would be able to solve like watch this video feed have have the agent like alert when something happens differently in the video feed well you're not there's no like API that would be logical for that and any AP API would eventually just approximate what the browser use was doing. It would be a video in API and that's all that that's all the browser use effectively is anyway. And so so I think we have some really cool use cases like like I wouldn't I wouldn't limit our imagination to agents with browsers as basically just in just using software. I would start to say what happens when you have a basically a full computer screen with unlimited data input as as a data feed and then an agent able to operate on that. what new use case could you go and have uh for AI agents and I think that will that will you know absolutely be 10x bigger than we think.
Yeah. And and do you foresee a future where the signal to noise ratio becomes so skewed because of I'll just say AI slop but whatever AI AI production of assets on the internet that humans aren't actually visiting websites and there's basically an agent between myself and the web.
I'm I'm nervous about slop for sure. I'm very nervous about slop. Uh, you know, when you think about things like V3, you're just like, "Oh my god, in in two years from now, I just I don't know what what what videos will be real. I barely know what text is real." Um, uh, so I'm I'm concerned about AI slop unquestionably. I think ways of verifying, you know, human generated content online will become very interesting. um agents as an intermediary between me and the internet um I think is sort of to me a little bit independent of the slot factor and it's more of just a natural byproduct of just our overall agentic use and you see things like comet from perplexity that like you know clearly we're going to have agents somewhere in the flow of our browser or internet use in the future and there's a lot of kind of cool ideas that that get opened up. So um uh you know imagine a world where you're giving agents you know various tasks a research task and that agent has a certain amount of budget that it can use for that research task and all of a sudden you know like one of the counter problems for the the you know AI training uh on the internet is that you're going to get more and more private sources of data that get more closed up. But then the the solution to that is, you know, agents with a budget that can basically pay that data provider to access information, you know, due to your query. Like we're gonna have some new forms of what agents are now capable of as a result of how the internet evolves due to agents. So, so there could be like some really interesting new innovations that maybe we never would have gotten if we were just humans on the internet and and we didn't have all of this automation that was occurring. I I'm a bit nervous about the orders of magnitude increase in the echochamber effect. Very similar to how we saw in social media, the algorithms feeding you what you already want to see or kind of amplifying fear, anger.
I can imagine if there's an agent between me and the entire ocean, the web of information that that issue might become more much more substantial than it is today.
Yeah. I think it's um uh I'm I'm just glad to not be running a social network.
So, um, that doesn't sound enjoyable at all to try and defend against this.
Yeah. Yeah. All right. Um, in the B2B space, like we have different other hard problems and fortunately, it's not the botification of uh of kind of corporations yet.
Where are companies overestimating AI capabilities today? Where do you think and then on the flip side to that, where are they underestimating? Because you're you're deep in it. You're deploying it internally. You're helping your customers deploy it. I don't get too much on the overestimation side. what I get is a laundry list of is AI ready for this thing and and what what gives me so much uh optimism and excitement is that list of of you know when I go and you know we we constantly host these sort of 10 or 15 person roundt you know conversations with a bunch of CIOS um chief information officers of companies and we get to kind of hear all their use cases and the use cases just grow and grow and grow and they are more and more imaginative one asterisk back to the earlier part of the conversation.
Interesting. Most of them are not about labor replacement. It's all usually about capability expansion of like I have this set of things that my company was never able to get around to and now agents being able to go and do that would unlock something for me. Like I've got like a million contracts and if a agents could just read all those contracts, I could then do this new thing as a business. or if agents could go in and you know summarize this information or take all my you know chat logs with with customers I get new sentiment analysis like all things that they never deployed humans at and it's just agents being able to solve those use cases. So in the first category I think I think um we're getting limited amounts of overestimation and more just like can AI do this when is it going to be possible to do that what you know can we deploy in this way which is great because it means that there's that that is proof that there's going to be dozens or hundreds of great new startups that can go and solve those problems as well as opportunities for the boxes and sales forces and service now of the world on the second category where we're underestimating the use um I think it's mostly in back to this category of how we work differently. I think I think people have not 100% sort of changed their mental model of their relationship with computers to fully kind of capture the the the sort of relationship of I deploy something to an AI system and then I review its work and I and I I help incorporate that work. Just that core premise is it's just very different from how we used software before. And so you get to this this kind of use case where people will try something with AI and maybe they don't sort of like they're like sort of okay that turned out okay or I didn't like it but they kind of imagine like their job is just to either take the whole thing or or nothing.
Yeah. and it either like did it well or didn't do it well. When actually in reality like you should just use it to create some critical mass of the thing you were trying to do and that should hopefully have solved hours or days worth of work and you should anticipate that it's going to be off by two or three or 5% and so you have to go through and review it. But once you are comfortable with that and you flip your mental model all of a sudden you can just get so much more done. Um and there's just so many more use cases that are now possible. I I had this um we did this uh survey recently with um with a bunch of um with a bunch of of IT leaders on kind of AI usage in the enterprise and uh I used AI to go and and um uh I used AI to go and produce the survey, the base the base sort of raw raw skeleton of the survey and it saved me like three to five hours of of like thinking about like all the different things and and it was just like this incredible sort of starting point to work off of and it just like but like I had to still modify a few things, but like it just saved hours and hours that I probably would have punted, which would have meant that we wouldn't have done the project in the first place because I wouldn't have had something to go pitch the team on and and it just like shortcuted a whole amount of work.
I still had to do lots of editing, but I was comfortable with the the baseline that it started with just to launch me into this project. And so if you have that mindset, you will find five times more ways to use AI in your organization if you're comfortable with the idea that yeah, the human is still going to have to do work. Like the we have not automated the whole thing yet. Like there's still this longtail that everything is going to run into. glad you said that. And this is this is the last question for you. You are extremely prolific on X. Uh you you put out a lot of great content. Where is AI helping you in there? Is it writing your post for you? uh like what what does that what does that balance look like and yeah what does your workflow yeah so for for stuff like on X or let's say LinkedIn or whatever just like if I'm if I'm posting a a thought on some AI topic that's essentially all me like okay short of a spelling kind of thing if I'm just like okay is it is it are or is like sometimes I'm just like okay that's a that's a you know how do I how do I make sure that one's right and the reason that I I still force myself to write all of that is simply because the space is changing so fast And I need to make sure that I'm comfortable myself in my understanding of it.
Yeah. It's and and I I'm like I think, you know, PG is like a big, you know, kind of obviously thought leader on on this on just like like writing is this just important skill and I I I think I grew up that way in in thinking about strategy memos and and and like and just how do you really think through everything that that you're working on. Um so so I I write it all. Um and um uh and it's it's like I I enjoy it. Um, and it forces me to, you know, again, kind of like think through like all of the consequences, all of the downstream effects of what's happening.
Now, what catalyzes the the writing is usually something that's happening in in the real world. So, I'll come from a conversation with our head of engineering or our CTO. I'll get out of a meeting with a customer. I'll see some breakthrough and then that sparks, okay, like what will agents do in this case? What will the business model be in that case? It's like anytime I'm writing about like business models of AI agents, you can almost guarantee that two hours prior there was a conversation internally about the business model of AI agents a box and I'm just kind of capturing some of these inherent questions that we kind of run into on those topics.
Are you ideiating with AI or are you kind of not for that stuff? Not for that stuff. Aaron, thank you very much for talking with me today. show seeing it.